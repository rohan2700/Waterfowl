# ğŸ¦† Waterfowl Detection in UAV Thermal Imagery

Automated detection of waterfowl in aerial imagery using deep learning for wildlife conservation. This project implements YOLOv8 for real-time object detection, comparing thermal-only and RGB-thermal fusion approaches.

![Sample Detection](results/sample_detections.jpg)

---

## ğŸ“‹ Table of Contents
- [Overview](#overview)
- [Dataset](#dataset)
- [Methodology](#methodology)
- [Results](#results)
- [Installation](#installation)
- [Usage](#usage)
- [Project Structure](#project-structure)
- [Key Findings](#key-findings)
- [Future Work](#future-work)
- [References](#references)
- [License](#license)

---

## ğŸ¯ Overview

### Problem Statement
Wildlife conservation increasingly relies on UAVs for non-invasive monitoring. Manual counting of animals in aerial imagery is time-consuming, error-prone, and limited in scale. This project develops an automated system to detect waterfowl using deep learning.

### Objectives
1. Build a thermal-only baseline detection model
2. Implement RGB-thermal fusion for improved accuracy
3. Compare both approaches quantitatively and qualitatively
4. Analyze strengths, weaknesses, and deployment considerations

### Why This Matters
- ğŸŒ **Conservation Impact**: Enable large-scale population monitoring
- ğŸš **UAV Technology**: Leverage aerial platforms for wildlife surveys
- ğŸ¤– **Automation**: Replace manual counting with AI-powered detection
- ğŸ“Š **Data-Driven**: Support evidence-based conservation decisions

---

## ğŸ“Š Dataset

**Source**: [UAV-derived Waterfowl Thermal Imagery Dataset](https://data.mendeley.com/datasets/46k66mz9sz/2)

### Dataset Composition:
- **Thermal Images**: 512Ã—640 pixels (.tif format)
- **RGB Images**: 3000Ã—4000 pixels (.jpg format)
- **Annotations**: CSV format with bounding boxes
- **Total Images**: 542 positive samples + negative samples
- **Bounding Boxes**: 8,975 annotations (all 7Ã—7 pixels in thermal space)

### Data Split:
- Training: 70%
- Validation: 20%
- Test: 10%

---

## ğŸ”¬ Methodology

### Approach 1: Thermal-Only Detection (Baseline)

**Model**: YOLOv8n (Nano)

**Pipeline**:
1. Load thermal images (512Ã—640)
2. Convert single-channel to 3-channel (RGB format for YOLO)
3. Convert annotations to YOLO format
4. Train with data augmentation
5. Evaluate on test set

**Advantages**:
- âœ… Simple pipeline
- âœ… Fast inference
- âœ… Weather/lighting independent
- âœ… Good thermal contrast

**Limitations**:
- âŒ Low resolution
- âŒ Limited visual features
- âŒ Difficulty with small objects (7Ã—7 pixels)

---

### Approach 2: RGB-Thermal Fusion (Improved)

**Model**: YOLOv8s (Small)

**Pipeline**:
1. Load both RGB and thermal images
2. **Critical Step**: Calculate scale factors
```python
   x_scale = 4000 / 640 = 6.25
   y_scale = 3000 / 512 = 5.86
```
3. Resize thermal to match RGB dimensions (3000Ã—4000)
4. **Early Fusion**: Create [Thermal, Green, Red] channel image
5. **Scale bounding boxes** from thermal space to RGB space
6. Train on high-resolution fused images

**Fusion Strategy**:
```
Standard RGB:  [R, G, B]
Our Fusion:    [Thermal, G, R]
                â†‘
         Replace Blue with Thermal
```

**Why This Works**:
- Combines heat signatures (thermal) with visual context (RGB)
- Leverages pre-trained RGB models
- Higher resolution (6.25Ã— width, 5.86Ã— height)
- Single inference pass (efficient)

---

## ğŸ“ˆ Results

### Quantitative Comparison

| Metric | Thermal-Only | RGB-Thermal Fusion | Improvement |
|--------|--------------|-------------------|-------------|
| **mAP50** | [Your Result] | 0.834 | +XX% |
| **mAP50-95** | [Your Result] | 0.371 | +XX% |
| **Precision** | [Your Result] | [Your Result] | +XX% |
| **Recall** | [Your Result] | [Your Result] | +XX% |

### Training Progress

![Thermal Results](results/thermal_results.png)
![Fusion Results](results/fusion_results.png)

### Key Observations

**Thermal-Only**:
- mAP50: [Your Result]
- Good performance considering low resolution
- Fast inference suitable for edge deployment

**RGB-Thermal Fusion**:
- mAP50: 0.834 (83.4% detection accuracy)
- Significant improvement from higher resolution
- Better localization accuracy (44Ã—41 pixel boxes vs 7Ã—7)

---

## ğŸ› ï¸ Installation

### Prerequisites
- Python 3.8+
- CUDA-capable GPU (recommended) or Apple Silicon (MPS)
- 16GB+ RAM

### Setup

1. **Clone the repository**
```bash
git clone https://github.com/YOUR_USERNAME/waterfowl_detection.git
cd waterfowl_detection
```

2. **Create virtual environment**
```bash
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate
```

3. **Install dependencies**
```bash
pip install -r requirements.txt
```

4. **Download dataset**
- Download from [Mendeley Data](https://data.mendeley.com/datasets/46k66mz9sz/2)
- Extract to project root
- Update paths in YAML files

---

## ğŸš€ Usage

### 1. Data Preparation

Open `waterfowl_detection_notebook.ipynb` and run the data preparation sections:
- Creates YOLO-format datasets
- Handles coordinate scaling for fusion
- Splits into train/val/test

### 2. Training Thermal Model
```python
from ultralytics import YOLO

# Load pre-trained model
model = YOLO('yolov8n.pt')

# Train
results = model.train(
    data='thermal_data.yaml',
    epochs=100,
    imgsz=640,
    batch=16
)
```

### 3. Training Fusion Model
```python
# Load larger model for fusion
model = YOLO('yolov8s.pt')

# Train on fused data
results = model.train(
    data='fusion_data.yaml',
    epochs=100,
    imgsz=640,
    batch=8
)
```

### 4. Evaluation
```python
# Evaluate on test set
metrics = model.val(
    split='test',
    conf=0.25
)

print(f"mAP50: {metrics.box.map50}")
print(f"mAP50-95: {metrics.box.map}")
```

### 5. Inference
```python
# Run inference on new images
results = model.predict(
    source='path/to/images',
    conf=0.25,
    save=True
)
```

---

## ğŸ“ Project Structure
```
waterfowl_detection/
â”œâ”€â”€ waterfowl_detection_notebook.ipynb  # Main notebook
â”œâ”€â”€ README.md                           # This file
â”œâ”€â”€ requirements.txt                    # Dependencies
â”œâ”€â”€ thermal_data.yaml                   # Thermal model config
â”œâ”€â”€ fusion_data.yaml                    # Fusion model config
â”œâ”€â”€ .gitignore                         # Git ignore rules
â”‚
â”œâ”€â”€ results/                           # Sample results
â”‚   â”œâ”€â”€ thermal_results.png
â”‚   â”œâ”€â”€ fusion_results.png
â”‚   â””â”€â”€ sample_detections.jpg
â”‚
â””â”€â”€ [Dataset folders - not uploaded]
    â”œâ”€â”€ 01_Positive_Image/
    â”œâ”€â”€ 03_Negative_Images/
    â”œâ”€â”€ 01_RGB_Images/
    â””â”€â”€ Bounding Box Label.csv
```

---

## ğŸ” Key Findings

### 1. Resolution is Critical
- Thermal: 7Ã—7 pixel objects
- Fusion: 44Ã—41 pixel objects (scaled)
- **6Ã— larger boxes dramatically improve detection**

### 2. Early Fusion is Effective
- Simple channel replacement works well
- No architecture changes needed
- Single inference pass (efficient)

### 3. Coordinate Scaling is Essential
```python
# Must scale coordinates from thermal to RGB space
x_scaled = x_thermal * (rgb_width / thermal_width)
y_scaled = y_thermal * (rgb_height / thermal_height)
```
**Failure to scale = boxes in wrong locations!**

### 4. Small Object Detection Challenges
- Even with fusion, 7Ã—7 pixel objects are difficult
- All annotations same size (no scale variation)
- High IoU thresholds are very strict

### 5. Trade-offs

| Aspect | Thermal-Only | Fusion |
|--------|--------------|--------|
| **Accuracy** | High | Moderate |
| **Speed** | Fast | Moderate |
| **Complexity** | Simple | Complex |
| **Hardware** | Thermal only | RGB + Thermal |
| **Deployment** | Edge-friendly | Requires more compute |

---

## ğŸš Deployment Recommendations

### For Bounding Box Accuracy-Critical Applications:
âœ… **Use Fusion Model**
- Research-grade data collection
- Population surveys
- Conservation monitoring

### For Real-Time Edge Deployment:
âœ… **Consider Thermal-Only**
- Drone battery constraints
- Real-time processing requirements
- Simpler hardware setup

### Optimize Further:
- Model quantization (INT8)
- TensorRT optimization
- Pruning for efficiency

---

## ğŸ”® Future Work

1. **Dataset Expansion**
   - Collect more diverse environments
   - Include varied bird sizes/distances
   - Multiple species classification

2. **Architecture Improvements**
   - Late fusion (ensemble approach)
   - Attention mechanisms
   - Multi-scale feature pyramids

3. **Temporal Integration**
   - Video sequence analysis
   - Object tracking across frames
   - Behavior pattern recognition

---

## ğŸ“š References

1. Dataset: UAV-derived Waterfowl Thermal Imagery Dataset, Mendeley Data (2020)
   https://data.mendeley.com/datasets/46k66mz9sz/2

2. Ultralytics YOLOv8 Documentation
   https://docs.ultralytics.com/

3. Redmon et al., "You Only Look Once: Unified, Real-Time Object Detection" (2016)

4. Jocher et al., "YOLOv5: State-of-the-Art Object Detection" (2020)

---

## ğŸ‘¤ Author

**Rohan Sanjay Patil**
- Course: Computer Vision
- Institution: THWS
- Date: November 2024

---

## ğŸ“„ License

This project is licensed under the MIT License - see the LICENSE file for details.

---

## ğŸ™ Acknowledgments

- Dataset creators for making this research possible
- Ultralytics team for YOLOv8 framework
- Conservation community for ongoing efforts to protect waterfowl populations

---

## ğŸ“§ Contact

For questions or collaboration:
- Email: [rohansanjaypatilrsp18@gmail.com]
- GitHub: [@rohan2700]

---

**â­ If you found this project helpful, please consider giving it a star!**
